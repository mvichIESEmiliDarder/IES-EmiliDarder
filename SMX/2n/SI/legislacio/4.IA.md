# Diapositiva 6.1: El AI Act – Clasificación por Riesgo

## No todas las IAs son iguales ante la ley

Europa no regula la tecnología, sino el **uso** que se hace de ella. Divide la IA en cuatro niveles:

* **Riesgo Inaceptable (PROHIBIDAS):**
* Sistemas de "puntuación social" (estilo Black Mirror).
* Manipulación cognitiva o conductual.
* Identificación biométrica remota en tiempo real en espacios públicos (salvo terrorismo/crimen grave).


* **Alto Riesgo (Muy Reguladas):** IAs usadas en educación (evaluar exámenes), empleo (filtrar CVs), sanidad o gestión de infraestructuras críticas.
* **Riesgo Limitado (Transparencia):** Chatbots y generadores de imágenes. El usuario debe saber que interactúa con una máquina.
* **Riesgo Mínimo:** Filtros de spam o IAs en videojuegos (sin regulación adicional).

---

# Diapositiva 6.2: IA Generativa y Deepfakes

## Transparencia y Derechos de Autor

Debido al auge de herramientas como ChatGPT, Midjourney o Sora, la ley incluyó apartados específicos:

* **Etiquetado de Contenido:** En 2026, cualquier imagen, vídeo o audio generado o manipulado por IA (**Deepfakes**) debe llevar una marca de agua digital o etiqueta clara.
* **Respeto al Copyright:** Los desarrolladores de modelos de IA deben publicar un resumen detallado de qué datos (libros, fotos, artículos) usaron para entrenar a la máquina.
* **Modelos de "Propósito General":** Las empresas como OpenAI o Google deben pasar pruebas de seguridad sistémica para asegurar que su IA no pueda ayudar a crear armas biológicas o realizar ciberataques masivos.
* **Fuente:** Reglamento (UE) 2024/1689 (Ley de Inteligencia Artificial).

---

# Diapositiva 6.3: Implementación en España

## La AESIA y los Sandboxes

España ha querido ser la punta de lanza en Europa con dos iniciativas clave:

* **AESIA (Agencia Española de Supervisión de la IA):** Con sede en A Coruña, es la **primera agencia de este tipo en Europa**. Se encarga de inspeccionar que las empresas cumplan con el AI Act y de poner multas.
* **Sandbox Regulatorio:** Un "entorno de pruebas" donde el Gobierno permite a las empresas probar sus IAs bajo supervisión antes de lanzarlas, para asegurar que no violan derechos fundamentales.
* **Estrategia Nacional de IA (ENIA):** Plan de inversión para que España desarrolle una IA propia, ética y enfocada en el idioma español (Proyecto ILIA).
* **Fuente:** Real Decreto 817/2023 (Entorno de pruebas controlado).

---

# Diapositiva 6.4: Desafíos y Ética en 2026

## ¿Hacia dónde vamos?

El debate ya no es si la IA es útil, sino si es justa.

* **Sesgos Algorítmicos:** La ley obliga a auditar los datos para evitar que una IA sea racista o machista al conceder un seguro médico o un trabajo.
* **Soberanía Digital:** El impulso de la "Nube Europea" para no depender de servidores en EE.UU. o China.
* **Impacto Medioambiental:** Las empresas deben informar del consumo energético brutal que supone entrenar y mantener grandes modelos de IA.
* **Sanciones:** Al igual que el RGPD, las multas pueden llegar a los **35 millones de €** o el **7% de la facturación global**.

---

### Resumen

> "Con el **AI Act**, Europa ha decidido que la innovación no puede ir por delante de los derechos humanos. Si una IA es una 'caja negra' que nadie entiende y que toma decisiones sobre tu vida, en Europa esa IA es ilegal."
